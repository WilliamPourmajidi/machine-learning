{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9e5e7ea",
   "metadata": {},
   "source": [
    "\n",
    "# Module 5 â€” In-Class Activity (Solution)\n",
    "**Topic:** Ensemble Learning in Practice \n",
    "This notebook contains the **completed version** of the in-class ensemble learning activity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e1e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================\n",
    "# Step 1. Imports and setup\n",
    "# ============================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c839eeca",
   "metadata": {},
   "source": [
    "\n",
    "## Step 2. Generate a simple dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8af9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = 240\n",
    "\n",
    "DraftsSubmitted    = np.random.randint(0, 6,  n)\n",
    "PeerReviewsGiven   = np.random.randint(0, 11, n)\n",
    "MeetingsWithTA     = np.random.randint(0, 7,  n)\n",
    "OnTimeSubmissions  = np.random.randint(0, 11, n)\n",
    "WeekendCodingHours = np.random.randint(0, 16, n)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"DraftsSubmitted\": DraftsSubmitted,\n",
    "    \"PeerReviewsGiven\": PeerReviewsGiven,\n",
    "    \"MeetingsWithTA\": MeetingsWithTA,\n",
    "    \"OnTimeSubmissions\": OnTimeSubmissions,\n",
    "    \"WeekendCodingHours\": WeekendCodingHours\n",
    "})\n",
    "\n",
    "# Label generation\n",
    "score = (\n",
    "    1.0 * DraftsSubmitted\n",
    "  + 0.6 * (PeerReviewsGiven / 2.0)\n",
    "  + 0.9 * MeetingsWithTA\n",
    "  + 0.8 * (OnTimeSubmissions / 2.0)\n",
    "  + 0.3 * (WeekendCodingHours / 3.0)\n",
    ")\n",
    "prob = 1.0 / (1.0 + np.exp(-0.9 * (score - 6.5)))\n",
    "df[\"HighGrade\"] = (prob > 0.55).astype(int)\n",
    "\n",
    "display(df.head())\n",
    "print(\"HighGrade rate:\", df[\"HighGrade\"].mean().round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a29cf3a",
   "metadata": {},
   "source": [
    "\n",
    "## Step 3. Split and scale the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfe045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop(columns=[\"HighGrade\"])\n",
    "y = df[\"HighGrade\"]\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=7, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_tr_sc = scaler.fit_transform(X_tr)\n",
    "X_te_sc = scaler.transform(X_te)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3ef216",
   "metadata": {},
   "source": [
    "\n",
    "## Step 4. Train baseline models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf18cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = {}\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=500, random_state=7)\n",
    "lr.fit(X_tr_sc, y_tr)\n",
    "pred_lr = lr.predict(X_te_sc)\n",
    "results[\"Logistic Regression\"] = {\n",
    "    \"Accuracy\": accuracy_score(y_te, pred_lr),\n",
    "    \"F1\": f1_score(y_te, pred_lr)\n",
    "}\n",
    "\n",
    "# Decision Tree\n",
    "tree = DecisionTreeClassifier(max_depth=5, random_state=7)\n",
    "tree.fit(X_tr, y_tr)\n",
    "pred_tree = tree.predict(X_te)\n",
    "results[\"Decision Tree\"] = {\n",
    "    \"Accuracy\": accuracy_score(y_te, pred_tree),\n",
    "    \"F1\": f1_score(y_te, pred_tree)\n",
    "}\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=250, random_state=7)\n",
    "rf.fit(X_tr, y_tr)\n",
    "pred_rf = rf.predict(X_te)\n",
    "results[\"Random Forest\"] = {\n",
    "    \"Accuracy\": accuracy_score(y_te, pred_rf),\n",
    "    \"F1\": f1_score(y_te, pred_rf)\n",
    "}\n",
    "\n",
    "pd.DataFrame(results).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328010fe",
   "metadata": {},
   "source": [
    "\n",
    "## Step 5. Train ensemble models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae374c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Bagging (Tree)\n",
    "bag = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=5, random_state=7),\n",
    "    n_estimators=200,\n",
    "    random_state=7\n",
    ")\n",
    "bag.fit(X_tr, y_tr)\n",
    "pred_bag = bag.predict(X_te)\n",
    "results[\"Bagging (Tree)\"] = {\n",
    "    \"Accuracy\": accuracy_score(y_te, pred_bag),\n",
    "    \"F1\": f1_score(y_te, pred_bag)\n",
    "}\n",
    "\n",
    "# AdaBoost (shallow trees)\n",
    "ada = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=2, random_state=7),\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.5,\n",
    "    random_state=7\n",
    ")\n",
    "ada.fit(X_tr, y_tr)\n",
    "pred_ada = ada.predict(X_te)\n",
    "results[\"AdaBoost\"] = {\n",
    "    \"Accuracy\": accuracy_score(y_te, pred_ada),\n",
    "    \"F1\": f1_score(y_te, pred_ada)\n",
    "}\n",
    "\n",
    "pd.DataFrame(results).T.sort_values(\"F1\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cde5b0a",
   "metadata": {},
   "source": [
    "\n",
    "## Step 6. Visualize comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341afb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "comparison = pd.DataFrame(results).T.sort_values(\"F1\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.barh(comparison.index, comparison[\"F1\"], alpha=0.85, color=\"teal\")\n",
    "plt.xlabel(\"F1 Score\")\n",
    "plt.title(\"Model Comparison: Project Habits Dataset\")\n",
    "plt.grid(axis=\"x\", alpha=0.35)\n",
    "plt.show()\n",
    "\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42243440",
   "metadata": {},
   "source": [
    "\n",
    "### Interpretation\n",
    "\n",
    "- **Random Forest** typically performs best because it combines many decorrelated trees, reducing variance.  \n",
    "- **Bagging** improves Decision Tree stability but not as strongly as Random Forest.  \n",
    "- **AdaBoost** performs well when weak learners (shallow trees) complement each other sequentially by focusing on prior mistakes.  \n",
    "- Logistic Regression may underperform if nonlinear relationships exist.  \n",
    "- Comparing F1 scores highlights that ensemble techniques generally outperform single models in this noisy, human-like dataset.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
