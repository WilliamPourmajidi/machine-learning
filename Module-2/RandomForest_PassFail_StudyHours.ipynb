{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3163c98",
   "metadata": {},
   "source": [
    "# Random Forest Classification  \n",
    "## From a Single Decision Tree to an Ensemble Model\n",
    "\n",
    "### Context\n",
    "In the previous notebook, we trained a **single Decision Tree** to predict whether a student would **pass or fail** based on weekly study hours.\n",
    "\n",
    "In this notebook, we extend the *same problem* to demonstrate the power of **Random Forests**.\n",
    "\n",
    "### Key idea\n",
    "A Random Forest:\n",
    "- Trains **many decision trees**\n",
    "- Each tree sees a **slightly different view** of the data\n",
    "- Final predictions are made by **majority voting**\n",
    "\n",
    "This reduces overfitting and improves generalization.\n",
    "\n",
    "### Learning objectives\n",
    "- Understand why a single decision tree can be unstable\n",
    "- See how Random Forests reduce variance\n",
    "- Apply Random Forests to the *same dataset*\n",
    "- Interpret results in comparison with a single tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e40b525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core numerical and data handling libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine learning models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Evaluation tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f4ef36",
   "metadata": {},
   "source": [
    "## 1) Recreate the same dataset (40 students)\n",
    "\n",
    "To make a **fair comparison**, we use the same data-generating process\n",
    "as in the Decision Tree example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f443d5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "study_hours",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "passed",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "038b9762-94fc-47cb-b1c5-d208b26bb799",
       "rows": [
        [
         "0",
         "7",
         "1"
        ],
        [
         "1",
         "20",
         "1"
        ],
        [
         "2",
         "15",
         "1"
        ],
        [
         "3",
         "11",
         "1"
        ],
        [
         "4",
         "8",
         "0"
        ],
        [
         "5",
         "21",
         "1"
        ],
        [
         "6",
         "7",
         "0"
        ],
        [
         "7",
         "19",
         "1"
        ],
        [
         "8",
         "23",
         "1"
        ],
        [
         "9",
         "11",
         "1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_hours</th>\n",
       "      <th>passed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_hours  passed\n",
       "0            7       1\n",
       "1           20       1\n",
       "2           15       1\n",
       "3           11       1\n",
       "4            8       0\n",
       "5           21       1\n",
       "6            7       0\n",
       "7           19       1\n",
       "8           23       1\n",
       "9           11       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate study hours\n",
    "study_hours = np.random.randint(1, 25, size=40)\n",
    "\n",
    "# Base rule with noise\n",
    "passed = (study_hours >= 10).astype(int)\n",
    "noise_indices = np.random.choice(range(40), size=4, replace=False)\n",
    "passed[noise_indices] = 1 - passed[noise_indices]\n",
    "\n",
    "students_df = pd.DataFrame({\n",
    "    \"study_hours\": study_hours,\n",
    "    \"passed\": passed\n",
    "})\n",
    "\n",
    "students_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38ed97b",
   "metadata": {},
   "source": [
    "## 2) Trainâ€“test split\n",
    "\n",
    "We keep the split logic identical so that performance differences\n",
    "come from the **model**, not the data handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e837ccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = students_df[[\"study_hours\"]]\n",
    "y = students_df[\"passed\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726a2d57",
   "metadata": {},
   "source": [
    "## 3) Baseline: single Decision Tree (for comparison)\n",
    "\n",
    "This shallow tree mirrors the previous notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eae8eefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier(\n",
    "    max_depth=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "dt_pred = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
    "\n",
    "dt_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1536a4",
   "metadata": {},
   "source": [
    "## 4) Train a Random Forest classifier\n",
    "\n",
    "Key differences from a single tree:\n",
    "- Multiple trees (`n_estimators`)\n",
    "- Bootstrap sampling\n",
    "- Random feature selection at each split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3e47aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,      # number of trees\n",
    "    max_depth=3,           # keep trees shallow for interpretability\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "rf_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2c470c",
   "metadata": {},
   "source": [
    "## 5) Compare performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13725b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Accuracy",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "02703dd7-36eb-4100-832b-0d00bb8371b0",
       "rows": [
        [
         "0",
         "Decision Tree",
         "0.9"
        ],
        [
         "1",
         "Random Forest",
         "0.8"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Accuracy\n",
       "0  Decision Tree       0.9\n",
       "1  Random Forest       0.8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df = pd.DataFrame({\n",
    "    \"Model\": [\"Decision Tree\", \"Random Forest\"],\n",
    "    \"Accuracy\": [dt_accuracy, rf_accuracy]\n",
    "})\n",
    "\n",
    "comparison_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb4af1e",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "- The Random Forest typically achieves **higher or more stable accuracy**\n",
    "  than a single tree.\n",
    "- Even when accuracy is similar, Random Forest predictions tend to be\n",
    "  **less sensitive to noise**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff2c412",
   "metadata": {},
   "source": [
    "## 6) Detailed evaluation of Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8988852a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[4 0]\n",
      " [2 4]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         4\n",
      "           1       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.83      0.83      0.80        10\n",
      "weighted avg       0.87      0.80      0.80        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, rf_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, rf_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8971f3a5",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "- Fewer extreme errors compared to a single tree\n",
    "- Better balance between precision and recall\n",
    "- More reliable behavior on unseen students\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2588719",
   "metadata": {},
   "source": [
    "## 7) Apply Random Forest to a new class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5165d69",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- predicted_pass\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m new_class = pd.DataFrame({\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mstudy_hours\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[32m4\u001b[39m, \u001b[32m7\u001b[39m, \u001b[32m9\u001b[39m, \u001b[32m11\u001b[39m, \u001b[32m14\u001b[39m, \u001b[32m18\u001b[39m]\n\u001b[32m      3\u001b[39m })\n\u001b[32m      5\u001b[39m new_class[\u001b[33m\"\u001b[39m\u001b[33mpredicted_pass\u001b[39m\u001b[33m\"\u001b[39m] = rf_model.predict(new_class)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m new_class[\u001b[33m\"\u001b[39m\u001b[33mpass_probability\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mrf_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_class\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[32m1\u001b[39m]\n\u001b[32m      8\u001b[39m new_class\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\willi\\anaconda3\\envs\\william-ml-3-12-12\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:945\u001b[39m, in \u001b[36mForestClassifier.predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    943\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    944\u001b[39m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m945\u001b[39m X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[32m    948\u001b[39m n_jobs, _, _ = _partition_estimators(\u001b[38;5;28mself\u001b[39m.n_estimators, \u001b[38;5;28mself\u001b[39m.n_jobs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\willi\\anaconda3\\envs\\william-ml-3-12-12\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:637\u001b[39m, in \u001b[36mBaseForest._validate_X_predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    634\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    635\u001b[39m     ensure_all_finite = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m637\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    640\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    641\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X.indices.dtype != np.intc \u001b[38;5;129;01mor\u001b[39;00m X.indptr.dtype != np.intc):\n\u001b[32m    646\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\willi\\anaconda3\\envs\\william-ml-3-12-12\\Lib\\site-packages\\sklearn\\utils\\validation.py:2929\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2845\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate_data\u001b[39m(\n\u001b[32m   2846\u001b[39m     _estimator,\n\u001b[32m   2847\u001b[39m     /,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2853\u001b[39m     **check_params,\n\u001b[32m   2854\u001b[39m ):\n\u001b[32m   2855\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[32m   2856\u001b[39m \n\u001b[32m   2857\u001b[39m \u001b[33;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2927\u001b[39m \u001b[33;03m        validated.\u001b[39;00m\n\u001b[32m   2928\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2929\u001b[39m     \u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2930\u001b[39m     tags = get_tags(_estimator)\n\u001b[32m   2931\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags.target_tags.required:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\willi\\anaconda3\\envs\\william-ml-3-12-12\\Lib\\site-packages\\sklearn\\utils\\validation.py:2787\u001b[39m, in \u001b[36m_check_feature_names\u001b[39m\u001b[34m(estimator, X, reset)\u001b[39m\n\u001b[32m   2784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[32m   2785\u001b[39m     message += \u001b[33m\"\u001b[39m\u001b[33mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2787\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[31mValueError\u001b[39m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- predicted_pass\n"
     ]
    }
   ],
   "source": [
    "new_class = pd.DataFrame({\n",
    "    \"study_hours\": [4, 7, 9, 11, 14, 18]\n",
    "})\n",
    "\n",
    "new_class[\"predicted_pass\"] = rf_model.predict(new_class)\n",
    "new_class[\"pass_probability\"] = rf_model.predict_proba(new_class)[:, 1]\n",
    "\n",
    "new_class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d57eee8",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "- Predictions are smoother and more confident near the decision boundary\n",
    "- Probabilities reflect consensus across many trees\n",
    "- This is why Random Forests generalize better in practice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e48b96",
   "metadata": {},
   "source": [
    "## Final teaching summary\n",
    "\n",
    "- A **Decision Tree** is easy to interpret but unstable\n",
    "- A **Random Forest** trades a little interpretability for:\n",
    "  - better generalization\n",
    "  - reduced overfitting\n",
    "  - higher robustness to noise\n",
    "- In real systems, Random Forests are often a strong baseline\n",
    "  before moving to more complex models\n",
    "\n",
    "This progression mirrors how practitioners scale from\n",
    "simple models to ensemble methods.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "william-ml-3-12-12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
